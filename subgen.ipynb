{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a7d27db1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-05T13:35:43.981846Z",
     "iopub.status.busy": "2025-07-05T13:35:43.981478Z",
     "iopub.status.idle": "2025-07-05T13:35:43.986608Z",
     "shell.execute_reply": "2025-07-05T13:35:43.985697Z"
    },
    "papermill": {
     "duration": 0.011662,
     "end_time": "2025-07-05T13:35:43.988049",
     "exception": false,
     "start_time": "2025-07-05T13:35:43.976387",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !pip install pymupdf\n",
    "# !pip install pdfminer.six\n",
    "# \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "389ce003",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-05T13:35:43.995249Z",
     "iopub.status.busy": "2025-07-05T13:35:43.994880Z",
     "iopub.status.idle": "2025-07-05T13:36:15.501835Z",
     "shell.execute_reply": "2025-07-05T13:36:15.500866Z"
    },
    "papermill": {
     "duration": 31.512857,
     "end_time": "2025-07-05T13:36:15.503743",
     "exception": false,
     "start_time": "2025-07-05T13:35:43.990886",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“¥ Loading labels...\n",
      "ðŸ” Extracting training samples from XMLs and PDFs...\n",
      "âœ… Loaded 1028 samples. Label distribution: Counter({0: 758, 1: 270})\n",
      "\n",
      "ðŸ“Š Evaluation Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.97      0.95       152\n",
      "           1       0.91      0.76      0.83        54\n",
      "\n",
      "    accuracy                           0.92       206\n",
      "   macro avg       0.92      0.87      0.89       206\n",
      "weighted avg       0.92      0.92      0.91       206\n",
      "\n",
      "Best threshold: 0.30, F1: 0.8468\n",
      "ðŸ’¾ Model and vectorizer saved.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "from lxml import etree\n",
    "from collections import Counter\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, precision_recall_curve\n",
    "from sklearn.utils import resample\n",
    "\n",
    "# === Paths ===\n",
    "TRAIN_LABELS = \"/kaggle/input/make-data-count-finding-data-references/train_labels.csv\"\n",
    "XML_DIR = \"/kaggle/input/make-data-count-finding-data-references/train/XML\"\n",
    "PDF_DIR = \"/kaggle/input/make-data-count-finding-data-references/train/PDF\"\n",
    "MODEL_PATH = \"clf_model.joblib\"\n",
    "VECTORIZER_PATH = \"vectorizer.joblib\"\n",
    "BEST_THRESH_PATH = \"best_threshold.txt\"\n",
    "\n",
    "# === Load Labels ===\n",
    "print(\"ðŸ“¥ Loading labels...\")\n",
    "labels_df = pd.read_csv(TRAIN_LABELS)\n",
    "\n",
    "# === Utility Functions ===\n",
    "def extract_text_from_xml(file_path):\n",
    "    try:\n",
    "        tree = etree.parse(file_path)\n",
    "        return \" \".join(tree.xpath('//text()'))\n",
    "    except:\n",
    "        return \"\"\n",
    "\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    try:\n",
    "        with open(pdf_path, \"rb\") as f:\n",
    "            return f.read().decode(\"latin1\", errors=\"ignore\")\n",
    "    except:\n",
    "        return \"\"\n",
    "\n",
    "def extract_text(article_id):\n",
    "    xml_path = os.path.join(XML_DIR, article_id + \".xml\")\n",
    "    pdf_path = os.path.join(PDF_DIR, article_id + \".pdf\")\n",
    "    if os.path.exists(xml_path):\n",
    "        return extract_text_from_xml(xml_path)\n",
    "    elif os.path.exists(pdf_path):\n",
    "        return extract_text_from_pdf(pdf_path)\n",
    "    return \"\"\n",
    "\n",
    "def normalize_doi(doi):\n",
    "    doi = doi.strip().lower()\n",
    "    if doi.startswith(\"https://doi.org/\"):\n",
    "        return doi\n",
    "    if doi.startswith(\"doi:\"):\n",
    "        doi = doi[4:]\n",
    "    if doi.startswith(\"10.\"):\n",
    "        return \"https://doi.org/\" + doi\n",
    "    return doi\n",
    "\n",
    "def extract_references(text):\n",
    "    dois = re.findall(r'\\b10\\.\\d{4,9}/[-._;()/:a-z0-9]+', text, flags=re.I)\n",
    "    accessions = re.findall(r'\\b(GSE\\d+|E-[A-Z]+-\\d+|PRJ[EDNA]\\d+|PDB\\s*\\w+)\\b', text, flags=re.I)\n",
    "    references = set()\n",
    "    for doi in dois:\n",
    "        references.add(normalize_doi(doi))\n",
    "    for acc in accessions:\n",
    "        references.add(acc.replace(\" \", \"\").upper())\n",
    "    return references\n",
    "\n",
    "def clean_text(text):\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    text = re.sub(r'[^a-zA-Z0-9 ]', '', text)\n",
    "    return text.lower()\n",
    "\n",
    "# === Collect Training Data ===\n",
    "print(\"ðŸ” Extracting training samples from XMLs and PDFs...\")\n",
    "texts, labels = [], []\n",
    "\n",
    "for _, row in labels_df.iterrows():\n",
    "    article_id, dataset_id, label_type = row['article_id'], row['dataset_id'], row['type']\n",
    "    text = extract_text(article_id)\n",
    "    if not text:\n",
    "        continue\n",
    "    match = re.search(re.escape(dataset_id), text, flags=re.I)\n",
    "    if match:\n",
    "        snippet = text[max(match.start() - 600, 0):match.end() + 600].replace('\\n', ' ')\n",
    "    else:\n",
    "        snippet = text[:600]\n",
    "    cleaned = clean_text(snippet)\n",
    "    if \"methods\" in snippet.lower():\n",
    "        cleaned += \" in_methods\"\n",
    "    texts.append(cleaned)\n",
    "    labels.append(1 if label_type.lower() == \"primary\" else 0)\n",
    "\n",
    "print(f\"âœ… Loaded {len(texts)} samples. Label distribution: {Counter(labels)}\")\n",
    "\n",
    "# === TF-IDF Vectorization ===\n",
    "vectorizer = TfidfVectorizer(ngram_range=(1, 2), max_features=10000)\n",
    "X = vectorizer.fit_transform(texts)\n",
    "y = np.array(labels)\n",
    "\n",
    "# === Train/Test Split ===\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, stratify=y, test_size=0.2, random_state=42)\n",
    "\n",
    "# === Oversample Primary Class ===\n",
    "X_pos = X_train[y_train == 1]\n",
    "X_neg = X_train[y_train == 0]\n",
    "X_pos_up = resample(X_pos, replace=True, n_samples=X_neg.shape[0], random_state=42)\n",
    "y_pos_up = np.ones(X_pos_up.shape[0])\n",
    "X_train = np.vstack([X_neg.toarray(), X_pos_up.toarray()])\n",
    "y_train = np.hstack([np.zeros(X_neg.shape[0]), y_pos_up])\n",
    "\n",
    "# === Train RandomForest Classifier ===\n",
    "clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# === Evaluate ===\n",
    "y_pred_proba = clf.predict_proba(X_val)[:, 1]\n",
    "precisions, recalls, thresholds = precision_recall_curve(y_val, y_pred_proba)\n",
    "f1_scores = 2 * (precisions * recalls) / (precisions + recalls + 1e-6)\n",
    "best_idx = np.argmax(f1_scores)\n",
    "\n",
    "print(\"\\nðŸ“Š Evaluation Report:\")\n",
    "print(classification_report(y_val, clf.predict(X_val)))\n",
    "print(f\"Best threshold: {thresholds[best_idx]:.2f}, F1: {f1_scores[best_idx]:.4f}\")\n",
    "\n",
    "# === Save Model, Vectorizer, Threshold ===\n",
    "joblib.dump(clf, MODEL_PATH)\n",
    "joblib.dump(vectorizer, VECTORIZER_PATH)\n",
    "with open(BEST_THRESH_PATH, 'w') as f:\n",
    "    f.write(str(thresholds[best_idx]))\n",
    "print(\"ðŸ’¾ Model and vectorizer saved.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "23dc6662",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-05T13:36:15.510953Z",
     "iopub.status.busy": "2025-07-05T13:36:15.510654Z",
     "iopub.status.idle": "2025-07-05T13:36:22.749100Z",
     "shell.execute_reply": "2025-07-05T13:36:22.747923Z"
    },
    "papermill": {
     "duration": 7.24402,
     "end_time": "2025-07-05T13:36:22.750823",
     "exception": false,
     "start_time": "2025-07-05T13:36:15.506803",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ” Running inference on test set...\n",
      "âœ… submission.csv and debug_log.csv saved.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "from lxml import etree\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# === Paths ===\n",
    "TEST_XML_DIR = \"/kaggle/input/make-data-count-finding-data-references/test/XML\"\n",
    "TEST_PDF_DIR = \"/kaggle/input/make-data-count-finding-data-references/test/PDF\"\n",
    "SUBMISSION_FILE = \"submission.csv\"\n",
    "MODEL_PATH = \"clf_model.joblib\"\n",
    "VECTORIZER_PATH = \"vectorizer.joblib\"\n",
    "DEBUG_LOG = \"debug_log.csv\"\n",
    "BEST_THRESH_PATH = \"best_threshold.txt\"\n",
    "\n",
    "# === Load Model ===\n",
    "clf = joblib.load(MODEL_PATH)\n",
    "vectorizer = joblib.load(VECTORIZER_PATH)\n",
    "with open(BEST_THRESH_PATH, 'r') as f:\n",
    "    BEST_THRESH = float(f.read())\n",
    "\n",
    "# === Utility Functions ===\n",
    "def extract_text_from_xml(file_path):\n",
    "    try:\n",
    "        tree = etree.parse(file_path)\n",
    "        return \" \".join(tree.xpath('//text()'))\n",
    "    except:\n",
    "        return \"\"\n",
    "\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    try:\n",
    "        with open(pdf_path, \"rb\") as f:\n",
    "            return f.read().decode(\"latin1\", errors=\"ignore\")\n",
    "    except:\n",
    "        return \"\"\n",
    "\n",
    "def extract_text(article_id):\n",
    "    xml_path = os.path.join(TEST_XML_DIR, article_id + \".xml\")\n",
    "    pdf_path = os.path.join(TEST_PDF_DIR, article_id + \".pdf\")\n",
    "    if os.path.exists(xml_path):\n",
    "        return extract_text_from_xml(xml_path)\n",
    "    elif os.path.exists(pdf_path):\n",
    "        return extract_text_from_pdf(pdf_path)\n",
    "    return \"\"\n",
    "\n",
    "def normalize_doi(doi):\n",
    "    doi = doi.strip().lower()\n",
    "    if doi.startswith(\"https://doi.org/\"):\n",
    "        return doi\n",
    "    if doi.startswith(\"doi:\"):\n",
    "        doi = doi[4:]\n",
    "    if doi.startswith(\"10.\"):\n",
    "        return \"https://doi.org/\" + doi\n",
    "    return doi\n",
    "\n",
    "def extract_references(text):\n",
    "    dois = re.findall(r'\\b10\\.\\d{4,9}/[-._;()/:a-z0-9]+', text, flags=re.I)\n",
    "    accessions = re.findall(r'\\b(GSE\\d+|E-[A-Z]+-\\d+|PRJ[EDNA]\\d+|PDB\\s*\\w+)\\b', text, flags=re.I)\n",
    "    references = set()\n",
    "    for doi in dois:\n",
    "        references.add(normalize_doi(doi))\n",
    "    for acc in accessions:\n",
    "        references.add(acc.replace(\" \", \"\").upper())\n",
    "    return references\n",
    "\n",
    "def clean_text(text):\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    text = re.sub(r'[^a-zA-Z0-9 ]', '', text)\n",
    "    return text.lower()\n",
    "\n",
    "# === Inference ===\n",
    "print(\"ðŸ” Running inference on test set...\")\n",
    "submission_rows = []\n",
    "debug_log = []\n",
    "\n",
    "for fname in os.listdir(TEST_XML_DIR):\n",
    "    if not fname.endswith(\".xml\"):\n",
    "        continue\n",
    "    article_id = fname.replace(\".xml\", \"\")\n",
    "    text = extract_text(article_id)\n",
    "    if not text:\n",
    "        continue\n",
    "\n",
    "    refs = extract_references(text)\n",
    "    for dataset_id in refs:\n",
    "        match = re.search(re.escape(dataset_id), text, flags=re.I)\n",
    "        if match:\n",
    "            snippet = text[max(match.start() - 600, 0):match.end() + 600].replace(\"\\n\", \" \")\n",
    "        else:\n",
    "            snippet = text[:600]\n",
    "\n",
    "        cleaned = clean_text(snippet)\n",
    "        if \"methods\" in snippet.lower():\n",
    "            cleaned += \" in_methods\"\n",
    "\n",
    "        features = vectorizer.transform([cleaned])\n",
    "        prob = clf.predict_proba(features)[0, 1]\n",
    "        citation_type = \"Primary\" if prob >= BEST_THRESH else \"Secondary\"\n",
    "\n",
    "        submission_rows.append({\n",
    "            \"article_id\": article_id,\n",
    "            \"dataset_id\": dataset_id,\n",
    "            \"type\": citation_type\n",
    "        })\n",
    "\n",
    "        debug_log.append({\n",
    "            \"article_id\": article_id,\n",
    "            \"dataset_id\": dataset_id,\n",
    "            \"probability\": round(prob, 4),\n",
    "            \"predicted_type\": citation_type,\n",
    "            \"snippet\": snippet[:200].replace('\\n', ' ')\n",
    "        })\n",
    "\n",
    "# === Save Files ===\n",
    "submission_df = pd.DataFrame(submission_rows).drop_duplicates()\n",
    "submission_df.insert(0, \"row_id\", range(len(submission_df)))\n",
    "submission_df.to_csv(SUBMISSION_FILE, index=False)\n",
    "\n",
    "debug_df = pd.DataFrame(debug_log)\n",
    "debug_df.to_csv(DEBUG_LOG, index=False)\n",
    "\n",
    "print(\"âœ… submission.csv and debug_log.csv saved.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2896c626",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-05T13:36:22.758911Z",
     "iopub.status.busy": "2025-07-05T13:36:22.758540Z",
     "iopub.status.idle": "2025-07-05T13:36:22.765025Z",
     "shell.execute_reply": "2025-07-05T13:36:22.763925Z"
    },
    "papermill": {
     "duration": 0.012581,
     "end_time": "2025-07-05T13:36:22.766738",
     "exception": false,
     "start_time": "2025-07-05T13:36:22.754157",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import os\n",
    "# import re\n",
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# from lxml import etree\n",
    "# from scipy.sparse import hstack\n",
    "# from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "# from sklearn.linear_model import LogisticRegression\n",
    "# import joblib\n",
    "\n",
    "# # === Configuration ===\n",
    "# TEST_XML_FOLDER = \"/kaggle/input/make-data-count-finding-data-references/test/XML\"  # Change to your test XML path\n",
    "# OUTPUT_CSV = \"submission.csv\"\n",
    "# MODEL_PATH = \"/kaggle/working/clf_model.joblib\"\n",
    "# VECTORIZER_PATH = \"/kaggle/working/vectorizer.joblib\"\n",
    "# BEST_THRESHOLD = 0.54  # from training\n",
    "\n",
    "# # === Load Artifacts ===\n",
    "# clf = joblib.load(MODEL_PATH)\n",
    "# vectorizer = joblib.load(VECTORIZER_PATH)\n",
    "\n",
    "# def extract_text_from_xml(file_path):\n",
    "#     try:\n",
    "#         tree = etree.parse(file_path)\n",
    "#         return \" \".join(tree.xpath('//text()'))\n",
    "#     except Exception:\n",
    "#         return \"\"\n",
    "\n",
    "# def normalize_doi(doi):\n",
    "#     doi = doi.strip().lower()\n",
    "#     if doi.startswith(\"https://doi.org/\"):\n",
    "#         return doi\n",
    "#     if doi.startswith(\"doi:\"):\n",
    "#         doi = doi[4:]\n",
    "#     if doi.startswith(\"10.\"):\n",
    "#         return \"https://doi.org/\" + doi\n",
    "#     return doi\n",
    "\n",
    "# def extract_references(text):\n",
    "#     dois = re.findall(r'\\b10\\.\\d{4,9}/[-._;()/:a-z0-9]+', text, flags=re.I)\n",
    "#     accessions = re.findall(r'\\b(GSE\\d+|E-[A-Z]+-\\d+|PRJ[EDNA]\\d+|PDB\\s*\\w+)\\b', text, flags=re.I)\n",
    "#     references = set()\n",
    "\n",
    "#     for doi in dois:\n",
    "#         doi_full = normalize_doi(doi)\n",
    "#         references.add(doi_full)\n",
    "\n",
    "#     for acc in accessions:\n",
    "#         acc_clean = acc.replace(\" \", \"\").upper()\n",
    "#         references.add(acc_clean)\n",
    "\n",
    "#     return list(references)\n",
    "\n",
    "# def keyword_feature(text):\n",
    "#     keywords = ['this study', 'generated', 'deposited', 'we used', 'available at']\n",
    "#     return int(any(k in text.lower() for k in keywords))\n",
    "\n",
    "# # === Inference ===\n",
    "# submission_rows = []\n",
    "\n",
    "# for file_name in os.listdir(TEST_XML_FOLDER):\n",
    "#     if not file_name.endswith(\".xml\"):\n",
    "#         continue\n",
    "\n",
    "#     article_id = file_name.replace(\".xml\", \"\")\n",
    "#     xml_path = os.path.join(TEST_XML_FOLDER, file_name)\n",
    "#     text = extract_text_from_xml(xml_path)\n",
    "#     refs = extract_references(text)\n",
    "\n",
    "#     for dataset_id in refs:\n",
    "#         match = re.search(re.escape(dataset_id), text, flags=re.I)\n",
    "#         snippet = text[max(match.start() - 100, 0):match.end() + 100] if match else text[:150]\n",
    "#         snippet = snippet.replace('\\n', ' ')\n",
    "\n",
    "#         x_tfidf = vectorizer.transform([snippet])\n",
    "#         x_kw = np.array([keyword_feature(snippet)]).reshape(-1, 1)\n",
    "#         x_feat = hstack([x_tfidf, x_kw])\n",
    "\n",
    "#         prob = clf.predict_proba(x_feat)[:, 1][0]\n",
    "#         pred_type = \"Primary\" if prob >= BEST_THRESHOLD else \"Secondary\"\n",
    "\n",
    "#         submission_rows.append({\n",
    "#             \"article_id\": article_id,\n",
    "#             \"dataset_id\": dataset_id,\n",
    "#             \"type\": pred_type\n",
    "#         })\n",
    "\n",
    "# # === Save Submission ===\n",
    "# submission_df = pd.DataFrame(submission_rows).drop_duplicates()\n",
    "# submission_df.insert(0, \"row_id\", range(len(submission_df)))\n",
    "# submission_df.to_csv(OUTPUT_CSV, index=False)\n",
    "\n",
    "# print(f\"âœ… Submission file saved to: {OUTPUT_CSV}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "67923338",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-05T13:36:22.773997Z",
     "iopub.status.busy": "2025-07-05T13:36:22.773658Z",
     "iopub.status.idle": "2025-07-05T13:36:22.778428Z",
     "shell.execute_reply": "2025-07-05T13:36:22.777399Z"
    },
    "papermill": {
     "duration": 0.010093,
     "end_time": "2025-07-05T13:36:22.779936",
     "exception": false,
     "start_time": "2025-07-05T13:36:22.769843",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# pip install pymupdf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "73c3637f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-05T13:36:22.787132Z",
     "iopub.status.busy": "2025-07-05T13:36:22.786802Z",
     "iopub.status.idle": "2025-07-05T13:36:22.793161Z",
     "shell.execute_reply": "2025-07-05T13:36:22.792039Z"
    },
    "papermill": {
     "duration": 0.012137,
     "end_time": "2025-07-05T13:36:22.795019",
     "exception": false,
     "start_time": "2025-07-05T13:36:22.782882",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import os\n",
    "# import re\n",
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# import joblib\n",
    "# from lxml import etree\n",
    "# from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# # === Paths ===\n",
    "# TEST_XML_DIR = \"/kaggle/input/make-data-count-finding-data-references/test/XML\"\n",
    "# TEST_PDF_DIR = \"/kaggle/input/make-data-count-finding-data-references/test/PDF\"\n",
    "# SUBMISSION_FILE = \"submission.csv\"\n",
    "# MODEL_PATH = \"clf_model.joblib\"\n",
    "# BERT_MODEL = \"all-MiniLM-L6-v2\"\n",
    "\n",
    "# # === Load Model ===\n",
    "# clf = joblib.load(MODEL_PATH)\n",
    "# bert = SentenceTransformer(BERT_MODEL)\n",
    "\n",
    "# # === Threshold ===\n",
    "# BEST_THRESH = 0.56  # From training script\n",
    "\n",
    "# # === Utility Functions ===\n",
    "# def extract_text_from_xml(file_path):\n",
    "#     try:\n",
    "#         tree = etree.parse(file_path)\n",
    "#         return \" \".join(tree.xpath('//text()'))\n",
    "#     except:\n",
    "#         return \"\"\n",
    "\n",
    "# def extract_text_from_pdf(pdf_path):\n",
    "#     try:\n",
    "#         with open(pdf_path, \"rb\") as f:\n",
    "#             return f.read().decode(\"latin1\", errors=\"ignore\")\n",
    "#     except:\n",
    "#         return \"\"\n",
    "\n",
    "# def extract_text(article_id):\n",
    "#     xml_path = os.path.join(TEST_XML_DIR, article_id + \".xml\")\n",
    "#     pdf_path = os.path.join(TEST_PDF_DIR, article_id + \".pdf\")\n",
    "#     if os.path.exists(xml_path):\n",
    "#         return extract_text_from_xml(xml_path)\n",
    "#     elif os.path.exists(pdf_path):\n",
    "#         return extract_text_from_pdf(pdf_path)\n",
    "#     return \"\"\n",
    "\n",
    "# def normalize_doi(doi):\n",
    "#     doi = doi.strip().lower()\n",
    "#     if doi.startswith(\"https://doi.org/\"):\n",
    "#         return doi\n",
    "#     if doi.startswith(\"doi:\"):\n",
    "#         doi = doi[4:]\n",
    "#     if doi.startswith(\"10.\"):\n",
    "#         return \"https://doi.org/\" + doi\n",
    "#     return doi\n",
    "\n",
    "# def extract_references(text):\n",
    "#     dois = re.findall(r'\\b10\\.\\d{4,9}/[-._;()/:a-z0-9]+', text, flags=re.I)\n",
    "#     accessions = re.findall(r'\\b(GSE\\d+|E-[A-Z]+-\\d+|PRJ[EDNA]\\d+|PDB\\s*\\w+)\\b', text, flags=re.I)\n",
    "#     references = set()\n",
    "#     for doi in dois:\n",
    "#         doi_full = normalize_doi(doi)\n",
    "#         references.add(doi_full)\n",
    "#     for acc in accessions:\n",
    "#         acc_clean = acc.replace(\" \", \"\").upper()\n",
    "#         references.add(acc_clean)\n",
    "#     return references\n",
    "\n",
    "# # === Inference ===\n",
    "# print(\"ðŸ” Running inference on test set...\")\n",
    "# submission_rows = []\n",
    "\n",
    "# for fname in os.listdir(TEST_XML_DIR):\n",
    "#     if not fname.endswith(\".xml\"):\n",
    "#         continue\n",
    "#     article_id = fname.replace(\".xml\", \"\")\n",
    "#     text = extract_text(article_id)\n",
    "#     if not text:\n",
    "#         continue\n",
    "\n",
    "#     refs = extract_references(text)\n",
    "#     for dataset_id in refs:\n",
    "#         match = re.search(re.escape(dataset_id), text, flags=re.I)\n",
    "#         if match:\n",
    "#             snippet = text[max(match.start() - 100, 0):match.end() + 100].replace(\"\\n\", \" \")\n",
    "#         else:\n",
    "#             snippet = text[:150]\n",
    "\n",
    "#         embedding = bert.encode([snippet])\n",
    "#         prob = clf.predict_proba(embedding)[0, 1]\n",
    "#         citation_type = \"Primary\" if prob >= BEST_THRESH else \"Secondary\"\n",
    "\n",
    "#         submission_rows.append({\n",
    "#             \"article_id\": article_id,\n",
    "#             \"dataset_id\": dataset_id,\n",
    "#             \"type\": citation_type\n",
    "#         })\n",
    "\n",
    "# # === Save Submission ===\n",
    "# submission_df = pd.DataFrame(submission_rows).drop_duplicates()\n",
    "# submission_df.insert(0, \"row_id\", range(len(submission_df)))\n",
    "# submission_df.to_csv(SUBMISSION_FILE, index=False)\n",
    "# print(\"âœ… Submission file created as submission.csv\")\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 12656064,
     "sourceId": 82370,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 31040,
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 44.577616,
   "end_time": "2025-07-05T13:36:23.720779",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-07-05T13:35:39.143163",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
